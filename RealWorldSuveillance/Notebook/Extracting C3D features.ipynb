{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hx173149/C3D-tensorflow`\n",
    "- code review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/anomalydetection ['Anomaly-Videos-Part-1', 'Anomaly-Videos-Part-2', 'Anomaly-Videos-Part-3', 'Anomaly-Videos-Part-4', 'Normal_Videos_for_Event_Recognition', 'Testing_Normal_Videos', 'Training-Normal-Videos-Part-1', 'Training-Normal-Videos-Part-2', 'UCF_Crimes-Train-Test-Split'] 3\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-1 ['Abuse', 'Arrest', 'Arson', 'Assault'] 0\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-1\\Abuse [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-1\\Arrest [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-1\\Arson [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-1\\Assault [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-2 ['Burglary', 'Explosion', 'Fighting'] 0\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-2\\Burglary [] 100\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-2\\Explosion [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-2\\Fighting [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-3 ['RoadAccidents', 'Robbery', 'Shooting'] 0\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-3\\RoadAccidents [] 150\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-3\\Robbery [] 150\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-3\\Shooting [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-4 ['Shoplifting', 'Stealing', 'Vandalism'] 0\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-4\\Shoplifting [] 50\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-4\\Stealing [] 100\n",
      "E:/anomalydetection\\Anomaly-Videos-Part-4\\Vandalism [] 50\n",
      "E:/anomalydetection\\Normal_Videos_for_Event_Recognition ['videos'] 0\n",
      "E:/anomalydetection\\Normal_Videos_for_Event_Recognition\\videos [] 50\n",
      "E:/anomalydetection\\Testing_Normal_Videos ['Testing_Normal_Videos_Anomaly'] 0\n",
      "E:/anomalydetection\\Testing_Normal_Videos\\Testing_Normal_Videos_Anomaly [] 150\n",
      "E:/anomalydetection\\Training-Normal-Videos-Part-1 [] 430\n",
      "E:/anomalydetection\\Training-Normal-Videos-Part-2 [] 370\n",
      "E:/anomalydetection\\UCF_Crimes-Train-Test-Split ['Action_Regnition_splits', 'Anomaly_Detection_splits'] 0\n",
      "E:/anomalydetection\\UCF_Crimes-Train-Test-Split\\Action_Regnition_splits [] 9\n",
      "E:/anomalydetection\\UCF_Crimes-Train-Test-Split\\Anomaly_Detection_splits [] 2\n"
     ]
    }
   ],
   "source": [
    "for parent, dirnames, filenames in os.walk('E:/anomalydetection'):\n",
    "    print(parent, dirnames, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_data(filename, num_frames_per_clip=16):\n",
    "    ret_arr = []\n",
    "    s_index = 0\n",
    "    for parent, dirnames, filenames in os.walk(filename):\n",
    "        if (len(filenames) < num_frames_per_clip):\n",
    "            return [], s_index\n",
    "        filenames = sorted(filenames)\n",
    "        s_index = random.randint(0, len(filenames) - num_frames_per_clip)\n",
    "        for i in range(s_index, s_index + num_frames_per_clip):\n",
    "            image_name = str(filename) + '/' + str(filenames[i])\n",
    "            img = Image.open(image_name)\n",
    "            img_data = np.array(img)\n",
    "            ret_arr.append(img_data)\n",
    "        return ret_arr, s_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clip_and_label(filename, batch_size, start_pos=-1, num_frames_per_clip=16, crop_size=112, shuffle=False):\n",
    "    lines = open(filename, 'r')\n",
    "    data, label = [], []\n",
    "    batch_index, next_batch_start = 0, -1\n",
    "    lines = list(lines)\n",
    "    np_mean = np.load('crop_mean.npy').reshape([num_frames_per_clip, crop_size, crop_size, 3])\n",
    "    # Forcing shuffle, if start_pos is not specified\n",
    "    if start_pos < 0:\n",
    "        shuffle = True\n",
    "    if shuffle:\n",
    "        video_indices = range(len(lines))\n",
    "        random.seed(time.time())\n",
    "        random.shuffle(video_indices)\n",
    "    else:\n",
    "        # Process videos sequentially\n",
    "        video_indices = range(start_pos, len(lines))\n",
    "    for index in video_indices:\n",
    "        if (batch_index >= batch_size):\n",
    "            next_batch_start = index\n",
    "            break\n",
    "        line = lines[index].strip('\\n').split()\n",
    "        dirname = line[0]\n",
    "        tmp_label = line[1]\n",
    "        if not shuffle:\n",
    "            print(\"Loading a video clip from {}...\".format(dirname))\n",
    "        tmp_data, _ = get_frames_data(dirname, num_frames_per_clip)\n",
    "        img_datas = []\n",
    "        if (len(tmp_data) != 0):\n",
    "            for j in xrange(len(tmp_data)):\n",
    "                img = Image.fromarray(tmp_data[j].astype(np.uint8))\n",
    "                if (img.width > img.height):\n",
    "                    scale = float(crop_size) / float(img.height)\n",
    "                    img = np.array(cv2.resize(np.array(img), (int(img.width * scale + 1), crop_size))).astype(np.float32)\n",
    "                else:\n",
    "                    scale = float(crop_size) / float(img.width)\n",
    "                    img = np.array(cv2.resize(np.array(img), (crop_size, int(img.height * scale + 1)))).astype(np.float32)\n",
    "                crop_x = int((img.shape[0] - crop_size) / 2)\n",
    "                crop_y = int((img.shape[1] - crop_size) / 2)\n",
    "                img = img[crop_x:crop_x+crop_size, crop_y:crop_y+crop_size,:] - np_mean[j]\n",
    "                img_datas.append(img)\n",
    "            data.append(img_datas)\n",
    "            label.append(int(tmp_label))\n",
    "            batch_index = batch_index + 1\n",
    "            read_dirnames.append(dirname)\n",
    "\n",
    "    # pad (duplicate) data/label if less than batch_size\n",
    "    valid_len = len(data)\n",
    "    pad_len = batch_size - valid_len\n",
    "    if pad_len:\n",
    "        for i in range(pad_len):\n",
    "            data.append(img_datas)\n",
    "            label.append(int(tmp_label))\n",
    "\n",
    "    np_arr_data = np.array(data).astype(np.float32)\n",
    "    np_arr_label = np.array(label).astype(np.int64)\n",
    "\n",
    "    return np_arr_data, np_arr_label, next_batch_start, read_dirnames, valid_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c3d_model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Builds the C3D network\n",
    "\n",
    "Implements the inference pattern for model building.\n",
    "inference_c3d(): builds the model as far as si required for running the network\n",
    "forward to make predictions.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# The UCF-101 dataset has 101 clsasses\n",
    "NUM_CLASSES = 101\n",
    "\n",
    "# Images are cropped to (CROP_SIZE, CROP_SIZE)\n",
    "CROP_SIZE = 112\n",
    "CHANNELS = 3\n",
    "\n",
    "# Number of frames per video clip\n",
    "NUM_FRAMES_PER_CLIP = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d(name, l_input, w, b):\n",
    "    return tf.nn.bias_add(\n",
    "        tf.nn.conv3d(l_input, w, strides=[1, 1, 1, 1, 1], padding='SAME', name=name), \n",
    "        b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(name, l_input, k):\n",
    "    return tf.nn.max_pool3d(l_input, ksize=[1, k, 2, 2, 1], strides=[1, k, 2, 2, 1], padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_c3d(_X, _dropout, batch_size, _weights, _biases):\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv1 = conv3d('conv1', _X, _weights['wc1'], _biases['bc1'])\n",
    "    conv1 = tf.nn.relu(conv1, name='relu1')\n",
    "    pool1 = max_pool('pool1', conv1, k=1)\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv2 = conv3d('conv2', pool1, _weights['wc2'], _biases['bc2'])\n",
    "    conv2 = tf.nn.relu(conv2, name='relu2')\n",
    "    pool2 = max_pool('pool2', conv2, k=2)\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv3 = conv3d('conv3a', pool2, _weights['wc3a'], _biases['bc3a'])\n",
    "    conv3 = tf.nn.relu(conv3, name='relu3a')\n",
    "    conv3 = conv3d('conv3b', conv3, _weights['wc3b'], _biases['bc3b'])\n",
    "    conv3 = tf.nn.relu(conv3, name='relu3b')\n",
    "    pool3 = max_pool('pool3', conv3, k=2)\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv4 = conv3d('conv4a', pool3, _weights['wc4a'], _biases['bc4a'])\n",
    "    conv4 = tf.nn.relu(conv4, name='relu4a')\n",
    "    conv4 = conv3d('conv4b', conv4, _weights['wc4b'], _biases['bc4b'])\n",
    "    conv4 = tf.nn.relu(conv4, name='relu4b')\n",
    "    pool4 = max_pool('pool4', conv4, k=2)\n",
    "    \n",
    "    # Convolution Layer\n",
    "    conv5 = conv3d('conv5a', pool4, _weights['wc5a'], _biases['bc5a'])\n",
    "    conv5 = tf.nn.relu(conv5, name='relu5a')\n",
    "    conv5 = conv3d('conv5b', conv5, _weights['wc5b'], _biases['bc5b'])\n",
    "    conv5 = tf.nn.relu(conv5, name='relu5b')\n",
    "    pool5 = max_pool('pool5', conv5, k=2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    pool5 = tf.transpose(pool5, perm=[0, 1, 4, 2, 3])\n",
    "    dense1 = tf.reshape(pool5, [batch_size, _weights['wd1'].get_shape().as_list()[0]]) # Reshape conv3 output to fit dense layer input\n",
    "    dense1 = tf.matmul(dense1, _weights['wd1']) + _biases['bd1']\n",
    "    \n",
    "    dense1 = tf.nn.relu(dense1, name='fc1') # Relu activation\n",
    "    dense1 = tf.nn.dropout(dense1, _dropout)\n",
    "    \n",
    "    dense2 = tf.nn.relu(\n",
    "        tf.matmul(dense1, _weights['wd2']) + _biases['bd2'], \n",
    "        name='fc2') # Relu activation\n",
    "    dense2 = tf.nn.dropout(dense2, _dropout)\n",
    "    \n",
    "    # Output: class prediction\n",
    "    out = tf.matmul(dense2, _weights['out']) + _biases['out']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_c3d_ucf101.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains and Evaluates the MNIST network using a feed dictionary.\"\"\"\n",
    "import os\n",
    "import time\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "# import input_data\n",
    "# import c3d_model\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model parameters as external flags.\n",
    "flags = tf.app.flags\n",
    "gpu_num = 1 # Number of my pc's gpu is 1.\n",
    "flags.DEFINE_string('f', '', 'kernel')  # Jupyter notebook에서 사용시에만 필요\n",
    "flags.DEFINE_integer('max_steps', 5000, 'Number of steps to run trainer.')\n",
    "flags.DEFINE_integer('batch_size', 10, 'Batch size.')\n",
    "FLAGS = flags.FLAGS\n",
    "MOVING_AVERAGE_DECAY = 0.9999\n",
    "model_save_dir = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n",
    "                                                           NUM_FRAMES_PER_CLIP,\n",
    "                                                           CROP_SIZE,\n",
    "                                                           CROP_SIZE,\n",
    "                                                           CHANNELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int64, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradient(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "            grads.append(expanded_g)\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tower_loss(name_scope, logit, labels):\n",
    "    cross_entropy_mean = tf.reduce_mean(\n",
    "                    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "    tf.summary.scalar(name_scope + '_cross_entropy',\n",
    "                      crosS_entropy_mean)\n",
    "    # https://eyeofneedle.tistory.com/24 참고\n",
    "    weight_decay_loss = tf.get_collection('weightdecay_losses')\n",
    "    tf.summary.scalar(name_scope + '_weight_decay_loss', tf.reduce_mean(weight_decay_loss))\n",
    "    \n",
    "    # Calculate the total loss for the current tower.\n",
    "    total_loss = cross_entropy_mean + weight_decay_loss\n",
    "    tf.summary.scalar(name_scope + '_total_loss', tf.reduce_mean(total_loss))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tower_acc(logit, labels):\n",
    "    correct_pred = tf.equal(tf.argmax(logit, 1), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, wd):\n",
    "    var = _variable_on_cpu(name, shape, tf.contrib.layers.xavier_initializer())\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.nn.l2_loss(var) * wd\n",
    "        tf.add_to_collection('weightdecay_losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    # Get the sets of images and labels for training, validation, and\n",
    "    # Tell TensorFlow that the model will be built into the default Graph.\n",
    "    \n",
    "    # Create model directory\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    use_pertrained_model = True\n",
    "    model_filename = './sports1m_finetuning_ucf101.model'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.get_variable(\n",
    "            'global_step',\n",
    "            [],\n",
    "            initializer=tf.constant_initializer(value=0),\n",
    "            trainable=False)\n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(\n",
    "                        FLAGS.batch_size + gpu_num)\n",
    "        tower_grad1, tower_grad2 = [], []\n",
    "        logits = []\n",
    "        opt_stable = tf.train.AdamOptimizer(1e-4)\n",
    "        opt_finetuning = tf.train.AdamOptimizer(1e-3)\n",
    "        with tf.variable_scope('var_name') as var_scope:\n",
    "            weights = {\n",
    "                'wc1': _variable_with_weight_decay('wc1', [3, 3, 3, 3, 64], 0.0005),\n",
    "                'wc2': _variable_with_weight_decay('wc2', [3, 3, 3, 64, 128], 0.0005),\n",
    "                'wc3a': _variable_with_weight_decay('wc3a', [3, 3, 3, 128, 256], 0.0005),\n",
    "                'wc3b': _variable_with_weight_decay('wc3b', [3, 3, 3, 256, 256], 0.0005),\n",
    "                'wc4a': _variable_with_weight_decay('wc4a', [3, 3, 3, 256, 512], 0.0005),\n",
    "                'wc4b': _variable_with_weight_decay('wc4b', [3, 3, 3, 512, 512], 0.0005),\n",
    "                'wc5a': _variable_with_weight_decay('wc5a', [3, 3, 3, 512, 512], 0.0005),\n",
    "                'wc5b': _variable_with_weight_decay('wc5b', [3, 3, 3, 512, 512], 0.0005),\n",
    "                'wd1': _variable_with_weight_decay('wd1', [8192, 4096], 0.0005),\n",
    "                'wd2': _variable_with_weight_decay('wd2', [4096, 4096], 0.0005),\n",
    "                'out': _variable_with_weight_decay('wout', [4096, NUM_CLASSES], 0.0005)\n",
    "            }\n",
    "            biases = {\n",
    "                'bc1': _variable_with_weight_decay('bc1', [64], 0.000),\n",
    "                'bc2': _variable_with_weight_decay('bc2', [128], 0.000),\n",
    "                'bc3a': _variable_with_weight_decay('bc3a', [256], 0.000),\n",
    "                'bc3b': _variable_with_weight_decay('bc3b', [256], 0.000),\n",
    "                'bc4a': _variable_with_weight_decay('bc4a', [512], 0.000),\n",
    "                'bc4b': _variable_with_weight_decay('bc4b', [512], 0.000),\n",
    "                'bc5a': _variable_with_weight_decay('bc5a', [512], 0.000),\n",
    "                'bc5b': _variable_with_weight_decay('bc5b', [512], 0.000),\n",
    "                'bd1': _variable_with_weight_decay('bd1', [4096], 0.000),\n",
    "                'bd2': _variable_with_weight_decay('bd2', [4096], 0.000),\n",
    "                'out': _variable_with_weight_decay('bout', [NUM_CLASSES], 0.000),\n",
    "            }\n",
    "        for gpu_index in range(gpu_num):\n",
    "            with tf.device('/gpu:%d' % gpu_index):\n",
    "\n",
    "                varlist2 = [weights['out'], biases['out']]\n",
    "                varlist1 = list(\n",
    "                    set(weights.values() + biases.values()) - set(varlist2)\n",
    "                )\n",
    "                logit = inference_c3d(\n",
    "                    _X=images_placeholder[gpu_index * FLAGS.batch_size:(gpu_index+1) * FLAGS.batch_size],\n",
    "                    _dropout=0.5,\n",
    "                    batch_size=FLAGS.batch_size,\n",
    "                    _weights=weights,\n",
    "                    _biases=biases)\n",
    "                grads1 = opt_stable.compute_gradients(loss, varlist1)\n",
    "                grads2 = opt_finetuning.compute_gradients(loss, varlist2)\n",
    "                tower_grads1.append(grad1)\n",
    "                tower_grads2.append(grad2)\n",
    "                logits.append(logit)\n",
    "        logits = tf.concat(logits, axis=0)\n",
    "        accuracy = tower_acc(logits, labels_placeholder)\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        grads1 = average_gradient(tower_grads1)\n",
    "        grads2 = average_gradient(tower_grads2)\n",
    "        apply_gradient_op1 = opt_stable.apply_gradients(grads1)\n",
    "        apply_gradient_op2 = opt_finetuning.apply_gradients(grads2, global_step=global_step)\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "        train_op = tf.group(apply_gradient_op1, apply_gradient_op2, variables_averages_op)\n",
    "        null_op = tf.no_op()\n",
    "                \n",
    "        # Create a saver for writing training checkpoints.\n",
    "        saver = tf.train.Saver(weights.values() + biases.values())\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "        sess.run(init)\n",
    "        # https://goodtogreate.tistory.com/entry/Saving-and-Restoring\n",
    "        if os.path.isfile(model_filename) and use_pretrained_model:\n",
    "            saver.restore(sess, model_filename)\n",
    "                    \n",
    "        # Create summary writter\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./visual_logs/train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter('./visual_logs/test', sess.graph)\n",
    "        for step in range(FLAGS.max_steps):\n",
    "            start_time = time.time()\n",
    "            train_images, train_labels, _, _, _ = read_clip_and_label(\n",
    "                filename='list/train.list',\n",
    "                batch_size=FLAGS.batch_size * gpu_num,\n",
    "                num_frames_per_clip=NUM_FRAMES_PER_CLIP,\n",
    "                crop_size=CROP_SIZE,\n",
    "                shuffle=True)\n",
    "            sess.run(train_op,\n",
    "                     feed_dict={\n",
    "                         images_placeholder: train_images,\n",
    "                         labels_placeholder: train_labels,\n",
    "                     })\n",
    "            duration = time.time() - start_time\n",
    "            print('Step %d: %.3f sec' % (step, duration))\n",
    "                    \n",
    "            # Save a checkpoint and evaluate the model periodically.\n",
    "            if ((step % 10) == 0) or ((step + 1) == FLAGS.max_steps) :\n",
    "                saver.save(sess, \n",
    "                           os.path.join(\n",
    "                               model_save_dir, \n",
    "                               'c3d_ucf_model'), \n",
    "                           global_step=step)\n",
    "                print('Training Data Eval:')\n",
    "                summary, acc = sess.run(\n",
    "                    [merged, accuracy],\n",
    "                    feed_dict={\n",
    "                        images_placeholder: train_images,\n",
    "                        labels_placeholder: train_labels,\n",
    "                    })\n",
    "                print('accuracy: {:.5f}'.format(acc))\n",
    "                train_writer.add_summary(summary, step)\n",
    "                print('Validation Data Eval:')\n",
    "                val_images, val_labels, _, _, _ = read_clip_and_label(\n",
    "                    filename='list/test.list',\n",
    "                    batch_size=FLAGS.batch_size * gpu_num,\n",
    "                    num_frames_per_clip=NUM_FRAMES_PER_CLIP,\n",
    "                    crop_size=CROP_SIZE,\n",
    "                    shuffle=True)\n",
    "                sumamry, acc = sess.run(\n",
    "                    [merged, accuracy],\n",
    "                    feed_dict={\n",
    "                        images_placeholder: val_images,\n",
    "                        labels_placeholder: val_labels,\n",
    "                    })\n",
    "                print('accuracy: {:.5f}'.format(acc))\n",
    "                test_writer.add_summary(summary, step)\n",
    "    print('Done')\n",
    "    \n",
    "def main(_):\n",
    "    run_training()\n",
    "    \n",
    "# tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_c3d_ucf101.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "# import tensorflow as tf\n",
    "# import input_data\n",
    "# import c3d_model\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model parameters as external flags.\n",
    "# flags = tf.app.flags\n",
    "# gpu_num = 1\n",
    "# flags.DEFINE_integer('batch_size', 10, 'Batch size.')\n",
    "# FLAGS = glags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n",
    "                                                           NUM_FRAMES_PER_CLIP,\n",
    "                                                           CROP_SIZE,\n",
    "                                                           CROP_SIZE,\n",
    "                                                           CHANNELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int64, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    var = _variable_on_cpu(name, shape, tf.truncated_normal_initializer(stddev=stddev))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.nn.l2_loss(var) * wd\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    model_name = \"./sports1m_finetuning_ucf101.model\"\n",
    "    test_list_file = 'list/test.list'\n",
    "    num_test_videos = len(list(open(test_list_file,'r')))\n",
    "    print(\"Number of test videos={}\".format(num_test_videos))\n",
    "    \n",
    "    # Get the sets of images and labels for trainig, validation, and\n",
    "    images_placeholder, labels_placeholder = placeholder_inputs(FLAGS.batch_size * gpu_num)\n",
    "    with tf.variable_scope('var_name') as var_scope:\n",
    "        weights = {\n",
    "            'wc1': _variable_with_weight_decay('wc1', [3, 3, 3, 3, 64], 0.04, 0.00),\n",
    "            'wc2': _variable_with_weight_decay('wc2', [3, 3, 3, 64, 128], 0.04, 0.00),\n",
    "            'wc3a': _variable_with_weight_decay('wc3a', [3, 3, 3, 128, 256], 0.04, 0.00),\n",
    "            'wc3b': _variable_with_weight_decay('wc3b', [3, 3, 3, 256, 256], 0.04, 0.00),\n",
    "            'wc4a': _variable_with_weight_decay('wc4a', [3, 3, 3, 256, 512], 0.04, 0.00),\n",
    "            'wc4b': _variable_with_weight_decay('wc4b', [3, 3, 3, 512, 512], 0.04, 0.00),\n",
    "            'wc5a': _variable_with_weight_decay('wc5a', [3, 3, 3, 512, 512], 0.04, 0.00),\n",
    "            'wc5b': _variable_with_weight_decay('wc5b', [3, 3, 3, 512, 512], 0.04, 0.00),\n",
    "            'wd1': _variable_with_weight_decay('wd1', [8192, 4096], 0.04, 0.001),\n",
    "            'wd2': _variable_with_weight_decay('wd2', [4096, 4096], 0.04, 0.002),\n",
    "            'out': _variable_with_weight_decay('wout', [4096, NUM_CLASSES], 0.04, 0.005)\n",
    "        }\n",
    "        biases = {\n",
    "            'bc1': _variable_with_weight_decay('bc1', [64], 0.04, 0.0),\n",
    "            'bc2': _variable_with_weight_decay('bc2', [128], 0.04, 0.0),\n",
    "            'bc3a': _variable_with_weight_decay('bc3a', [256], 0.04, 0.0),\n",
    "            'bc3b': _variable_with_weight_decay('bc3b', [256], 0.04, 0.0),\n",
    "            'bc4a': _variable_with_weight_decay('bc4a', [512], 0.04, 0.0),\n",
    "            'bc4b': _variable_with_weight_decay('bc4b', [512], 0.04, 0.0),\n",
    "            'bc5a': _variable_with_weight_decay('bc5a', [512], 0.04, 0.0),\n",
    "            'bc5b': _variable_with_weight_decay('bc5b', [512], 0.04, 0.0),\n",
    "            'bd1': _variable_with_weight_decay('bd1', [4096], 0.04, 0.0),\n",
    "            'bd2': _variable_with_weight_decay('bd2', [4096], 0.04, 0.0),\n",
    "            'out': _variable_with_weight_decay('bout', [NUM_CLASSES], 0.04, 0.0),\n",
    "        }\n",
    "    logits = []\n",
    "    for gpu_idnex in range(gpu_num):\n",
    "        with tf.device('/gpu:%d' % gpu_index):\n",
    "            logit = inference_c3d(\n",
    "                images_placeholder[\n",
    "                    gpu_index*FLAGS.batch_size:(gpu_index+1)*FLAGS.batch_size,\n",
    "                    :,:,:,:], \n",
    "                _dropout=0.6, batch_size=FLAGS.batch_size, \n",
    "                _weights=weights, _biases=biases)\n",
    "            logits.append(logit)\n",
    "    logits = tf.concat(logits, axis=0)\n",
    "    norm_score = tf.nn.softmax(logits)\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver.restore(sess, model_name)\n",
    "    # And then after everything is built, start the training loop\n",
    "    bufsize = 0\n",
    "    write_file = open('predict_ret.txt', 'w+', bufsize)\n",
    "    next_start_pos = 0\n",
    "    all_steps = int((num_test_videos - 1) / (FLAGS.batch_size*gpu_num) + 1)\n",
    "    for step in range(all_steps):\n",
    "        # Fill a feed dictionary with the actual set of images and labels\n",
    "        # for this particular training step.\n",
    "        test_images, test_labels, next_start_pos, _, valid_len = \\\n",
    "            read_clip_and_label(test_list_file,\n",
    "                                FLAGS.batch_size*gpu_num,\n",
    "                                start_pos=next_start_pos)\n",
    "        predict_score = norm_score.eval(\n",
    "            session=sess,\n",
    "            feed_dict={images_placeholder: test_images})\n",
    "        for i in range(valid_len):\n",
    "            true_label = test_labels[i]\n",
    "            top1_predicted_label = np.argmax(predict_score[i])\n",
    "            # Write results: true label, class prob for true label, predicted label, class prob for predicted label\n",
    "            write_file.write('{}, {}, {}, {}\\n'.format(\n",
    "                true_label[0],\n",
    "                predict_score[i][true_label],\n",
    "                top1_predicted_label,\n",
    "                predict_score[i][top1_predicted_label]))\n",
    "    write_file.close()\n",
    "    print('Done')\n",
    "    \n",
    "def main(_):\n",
    "    run_test()\n",
    "    \n",
    "# tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `OpenCV`, Video to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video to image (frames) conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'E:/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi'\n",
    "vidcap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n",
    "    hasFrames, image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite('image' + str(count) + '.jpg', image) # save frame as JPG file\n",
    "    return hasFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = 0\n",
    "frameRate = 0.5 # it will capture image in each 0.5 second\n",
    "count = 1\n",
    "success = getFrame(sec)\n",
    "while success:\n",
    "    count += 1\n",
    "    sec += frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
